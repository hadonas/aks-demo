from flask import Flask, request, jsonify, session
from flask_cors import CORS
import redis
import mysql.connector
import json
from datetime import datetime
import os
from kafka import KafkaProducer, KafkaConsumer
from functools import wraps
from werkzeug.security import generate_password_hash, check_password_hash
from threading import Thread
import threading
import logging
import sys
import traceback

# OpenTelemetry imports
from opentelemetry import trace, metrics
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.exporter.otlp.proto.http._log_exporter import OTLPLogExporter
from opentelemetry.exporter.otlp.proto.http.metric_exporter import OTLPMetricExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk._logs import LoggerProvider, LoggingHandler
from opentelemetry.sdk._logs.export import BatchLogRecordProcessor
from opentelemetry._logs import set_logger_provider
from opentelemetry.instrumentation.flask import FlaskInstrumentor
from opentelemetry.instrumentation.requests import RequestsInstrumentor
from opentelemetry.instrumentation.mysql import MySQLInstrumentor
from opentelemetry.instrumentation.redis import RedisInstrumentor
from opentelemetry.instrumentation.logging import LoggingInstrumentor
from opentelemetry.instrumentation.urllib3 import URLLib3Instrumentor
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST

# Prometheus ë©”íŠ¸ë¦­ ì •ì˜
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration', ['method', 'endpoint'])
ACTIVE_USERS = Gauge('active_users_total', 'Total active users')
DB_CONNECTIONS = Gauge('database_connections_active', 'Active database connections')
REDIS_CONNECTIONS = Gauge('redis_connections_active', 'Active Redis connections')

# ìë™ê³„ì¸¡ë§Œ ì‚¬ìš© (ìˆ˜ë™ ë©”íŠ¸ë¦­ ì œê±°)

# OpenTelemetry ì„¤ì •
def setup_opentelemetry():
    # ë¦¬ì†ŒìŠ¤ ì„¤ì • (OpenTelemetry í‘œì¤€ ì†ì„±)
    resource = Resource.create({
        "service.name": "aks-demo-backend",
        "service.version": "1.0.0",
        "deployment.environment": os.getenv("ENVIRONMENT", "production"),
        "service.instance.id": os.getenv("HOSTNAME", "backend-1"),
        "service.namespace": "aks-demo",
        "container.name": "backend",
        "telemetry.sdk.name": "opentelemetry",
        "telemetry.sdk.language": "python"
    })
    
    
    # TracerProvider ì„¤ì •
    tracer_provider = TracerProvider(resource=resource)
    trace.set_tracer_provider(tracer_provider)
    tracer = trace.get_tracer(__name__)
    
    
    
    # OTLP Exporter ì„¤ì • (ì™¸ë¶€ Collector ì‚¬ìš©) - HTTP ì‚¬ìš©
    otlp_endpoint = os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT", "http://collector.lgtm.20.249.154.255.nip.io")
    
    # ë””ë²„ê¹… ë¡œê·¸

    print(f"ğŸŒ Environment: {os.getenv('ENVIRONMENT', 'production')}")
    
    # Collector ì—°ê²° í…ŒìŠ¤íŠ¸
    import requests
    try:
        health_url = f"{otlp_endpoint}/health"
        response = requests.get(health_url, timeout=5)

    except Exception as e:
        pass
    
    # Trace Exporter ì„¤ì • (ê¸°ë³¸ í—¤ë” ì‚¬ìš©)
    otlp_exporter = OTLPSpanExporter(
        endpoint=f"{otlp_endpoint}/v1/traces",
        timeout=30,
    )

    
    # Span Processor ì„¤ì • (ìë™ê³„ì¸¡ ìµœì í™”)
    span_processor = BatchSpanProcessor(
        otlp_exporter,
        max_queue_size=2048,        # ë” í° í í¬ê¸°
        max_export_batch_size=512,  # ë” í° ë°°ì¹˜ í¬ê¸°  
        export_timeout_millis=30000,
        schedule_delay_millis=5000  # 5ì´ˆë§ˆë‹¤ ë°°ì¹˜ ì „ì†¡
    )
    tracer_provider.add_span_processor(span_processor)

    
    # Metrics Exporter ì„¤ì • (ê¸°ë³¸ í—¤ë” ì‚¬ìš©)
    metric_exporter = OTLPMetricExporter(
        endpoint=f"{otlp_endpoint}/v1/metrics",
        timeout=30,
    )

    
    # Metric Reader ì„¤ì • (ìë™ê³„ì¸¡ ìµœì í™”)
    metric_reader = PeriodicExportingMetricReader(
        exporter=metric_exporter,
        export_interval_millis=10000,  # 10ì´ˆë§ˆë‹¤ ë©”íŠ¸ë¦­ ì „ì†¡ (ìë™ê³„ì¸¡ì— ì í•©)
        export_timeout_millis=30000    # íƒ€ì„ì•„ì›ƒ 30ì´ˆ
    )

    
    meter_provider = MeterProvider(
        resource=resource,
        metric_readers=[metric_reader]
    )
    metrics.set_meter_provider(meter_provider)

    
    # LoggerProvider ì„¤ì • (ìë™ê³„ì¸¡ìš©)
    logger_provider = LoggerProvider(resource=resource)
    
    # Log Exporter ì„¤ì • (ê¸°ë³¸ í—¤ë” ì‚¬ìš©)
    log_exporter = OTLPLogExporter(
        endpoint=f"{otlp_endpoint}/v1/logs",
        timeout=30,
    )

    
    # Log Processor ì„¤ì • (ìë™ê³„ì¸¡ ìµœì í™”)
    log_processor = BatchLogRecordProcessor(
        log_exporter,
        max_queue_size=2048,        # ë” í° í í¬ê¸°
        max_export_batch_size=512,  # ë” í° ë°°ì¹˜ í¬ê¸°
        export_timeout_millis=30000,
        schedule_delay_millis=5000  # 5ì´ˆë§ˆë‹¤ ë°°ì¹˜ ì „ì†¡
    )
    logger_provider.add_log_record_processor(log_processor)
    set_logger_provider(logger_provider)
    
    # ìë™ ê³„ì¸¡ ì„¤ì • (Flask ì œì™¸ - ì•± ìƒì„± í›„ì— ë³„ë„ë¡œ ì„¤ì •)
    # ë°ì´í„°ë² ì´ìŠ¤ ë° ë„¤íŠ¸ì›Œí¬ ìë™ê³„ì¸¡
    RequestsInstrumentor().instrument()
    MySQLInstrumentor().instrument()
    RedisInstrumentor().instrument()
    URLLib3Instrumentor().instrument()
    
    # LoggingInstrumentor ì„¤ì • (ìë™ê³„ì¸¡ìœ¼ë¡œ ë¡œê·¸ ì „ì†¡)
    LoggingInstrumentor().instrument(
        set_logging_format=True,
        logging_format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        log_level=logging.INFO
    )
    
    # Python í‘œì¤€ ë¡œê±°ì— OpenTelemetry handler ì¶”ê°€
    otel_handler = LoggingHandler(
        level=logging.INFO,
        logger_provider=logger_provider
    )
    
    # Root loggerì— OpenTelemetry handler ì¶”ê°€
    root_logger = logging.getLogger()
    root_logger.addHandler(otel_handler)
    
    # ì•± ë¡œê±°ì—ë„ ì¶”ê°€
    app_logger = logging.getLogger(__name__)
    app_logger.addHandler(otel_handler)
    app_logger.setLevel(logging.INFO)
    


app = Flask(__name__)
CORS(app, supports_credentials=True)  # ì„¸ì…˜ì„ ìœ„í•œ credentials ì§€ì›
app.secret_key = os.getenv('FLASK_SECRET_KEY', 'your-secret-key-here')  # ì„¸ì…˜ì„ ìœ„í•œ ì‹œí¬ë¦¿ í‚¤

# ìë™ê³„ì¸¡ ì‚¬ìš©ìœ¼ë¡œ tracer ì „ì—­ ë³€ìˆ˜ ì œê±°

# ìë™ê³„ì¸¡ ë¡œê·¸ í…ŒìŠ¤íŠ¸
logging.info("AKS Demo Backend application started - Auto-instrumentation enabled")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ ë””ë²„ê¹… ì¶œë ¥
logger.info("=== í™˜ê²½ë³€ìˆ˜ í™•ì¸ ===")
logger.info(f"MARIADB_HOST: {os.getenv('MARIADB_HOST', 'NOT_SET')}")
logger.info(f"MARIADB_USER: {os.getenv('MARIADB_USER', 'NOT_SET')}")
logger.info(f"MARIADB_PASSWORD: {'****' if os.getenv('MARIADB_PASSWORD') else 'NOT_SET'}")
logger.info(f"REDIS_HOST: {os.getenv('REDIS_HOST', 'NOT_SET')}")
logger.info(f"KAFKA_SERVERS: {os.getenv('KAFKA_SERVERS', 'NOT_SET')}")
logger.info(f"OTEL_EXPORTER_OTLP_ENDPOINT: {os.getenv('OTEL_EXPORTER_OTLP_ENDPOINT', 'NOT_SET')}")
logger.info(f"OTEL_EXPORTER_OTLP_PROTOCOL: {os.getenv('OTEL_EXPORTER_OTLP_PROTOCOL', 'NOT_SET')}")
logger.info("===================")

# OpenTelemetry Collector ì—°ê²° í…ŒìŠ¤íŠ¸
def test_collector_connection():
    """Collector ì—°ê²° ìƒíƒœë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¤ì œ ë°ì´í„°ë¥¼ ì „ì†¡í•´ë³´ëŠ” í•¨ìˆ˜"""
    import requests
    import time
    
    otlp_endpoint = os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT", "http://collector.lgtm.20.249.154.255.nip.io")
    

    
    # 1. ê¸°ë³¸ HTTP ì—°ê²° í…ŒìŠ¤íŠ¸
    try:
        health_url = f"{otlp_endpoint}/health"
        response = requests.get(health_url, timeout=10)
    except Exception as e:
        pass
    
    # ìë™ê³„ì¸¡ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ìˆ˜ë™ span ìƒì„± ì œê±°

    
    # 3. ê°•ì œ flush ì‹œë„
    try:
        from opentelemetry.sdk.trace import TracerProvider
        tracer_provider = trace.get_tracer_provider()
        if hasattr(tracer_provider, 'force_flush'):
            tracer_provider.force_flush(timeout_millis=10000)  # 10ì´ˆë¡œ ëŠ˜ë¦¼
    except Exception as e:
        pass
    
    # 4. Metrics provider flush ì‹œë„
    try:
        meter_provider = metrics.get_meter_provider()
        if hasattr(meter_provider, 'force_flush'):
            meter_provider.force_flush(timeout_millis=10000)
    except Exception as e:
        pass

# Flask ì•± ì‹œì‘ í›„ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
def run_startup_tests():
    """ì•± ì‹œì‘ í›„ ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ë“¤"""

    test_collector_connection()
    
    # ë¡œê·¸ ì „ì†¡ í…ŒìŠ¤íŠ¸
    try:
        logger.info("OpenTelemetry log transmission test - INFO level")
        logger.warning("OpenTelemetry log transmission test - WARNING level")
        logger.error("OpenTelemetry log transmission test - ERROR level (for testing)")
        logger.debug("OpenTelemetry log transmission test - DEBUG level")
        
        # êµ¬ì¡°í™”ëœ ë¡œê·¸ í…ŒìŠ¤íŠ¸
        logger.info("Structured log test", extra={
            "user_id": "test_user",
            "action": "startup_test",
            "environment": os.getenv("ENVIRONMENT", "development"),
            "service": "aks-demo-backend"
        })
        

    except Exception as e:
        logger.error(f"Log transmission test failed: {str(e)}")
    
    # ìë™ê³„ì¸¡ ì‚¬ìš©ìœ¼ë¡œ ìˆ˜ë™ ë©”íŠ¸ë¦­ ì œê±°
    logger.info("Auto-instrumentation is collecting metrics")

# ì§€ì—°ëœ OpenTelemetry ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_opentelemetry():
    """ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œëœ í›„ OpenTelemetryë¥¼ ì´ˆê¸°í™”"""
    try:
        setup_opentelemetry()
        # Flask ì•±ì— ëŒ€í•œ instrumentation ì ìš© (ì•±ê³¼ ëª¨ë“  ì„¤ì • ì™„ë£Œ í›„)
        FlaskInstrumentor().instrument_app(app)
        
        # ì´ˆê¸°í™” í›„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        run_startup_tests()
        
    except Exception as e:
        pass

# ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜
def log_system_stats():
    """ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ë¡œê·¸ì— ê¸°ë¡í•˜ê³  ë©”íŠ¸ë¦­ ì „ì†¡"""
    try:
        # ìŠ¤ë ˆë“œ ìˆ˜
        thread_count = threading.active_count()
        logger.info(f"Thread count: {thread_count}")
        
        # ìë™ê³„ì¸¡ ì‚¬ìš©ìœ¼ë¡œ ìˆ˜ë™ ë©”íŠ¸ë¦­ ì œê±°
        
        # í”„ë¡œì„¸ìŠ¤ ID
        logger.info(f"Process PID: {os.getpid()}")
        
        # Redis ì—°ê²° ìƒíƒœ ì²´í¬
        try:
            redis_client = get_redis_connection()
            redis_info = redis_client.info()
            connected_clients = redis_info.get('connected_clients', 0)
            used_memory = redis_info.get('used_memory', 0)
            
            logger.info(f"Redis status - Connected clients: {connected_clients}")
            logger.info(f"Redis status - Used memory: {redis_info.get('used_memory_human', 'N/A')}")
            
            # ìë™ê³„ì¸¡ ì‚¬ìš©ìœ¼ë¡œ Redis ìˆ˜ë™ ë©”íŠ¸ë¦­ ì œê±°
                
            redis_client.close()
        except Exception as e:
            logger.warning(f"Redis status check failed: {str(e)}")
        
        # í™˜ê²½ ì •ë³´
        logger.info(f"Environment: {os.getenv('ENVIRONMENT', 'development')}")
        logger.info(f"OpenTelemetry endpoint: {os.getenv('OTEL_EXPORTER_OTLP_ENDPOINT', 'NOT_SET')}")
            
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)}")

# # ì£¼ê¸°ì  ì‹œìŠ¤í…œ ìƒíƒœ ë¡œê¹… (30ì´ˆë§ˆë‹¤)
# def schedule_system_monitoring():
#     """ì£¼ê¸°ì ìœ¼ë¡œ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§"""
#     log_system_stats()
#     threading.Timer(30.0, schedule_system_monitoring).start()  # 30ì´ˆë§ˆë‹¤ ì‹¤í–‰

# ì•± ì‹œì‘ í›„ ì§€ì—°ëœ OpenTelemetry ì´ˆê¸°í™” ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ)
threading.Timer(5.0, initialize_opentelemetry).start()

# ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (15ì´ˆ í›„)
# threading.Timer(15.0, schedule_system_monitoring).start()

# # ìŠ¤ë ˆë“œ í’€ ìƒì„±
# thread_pool = ThreadPoolExecutor(max_workers=5)

# MariaDB ì—°ê²° í•¨ìˆ˜
def get_db_connection():
    start_time = datetime.now()
    try:
        logger.info("=== MariaDB ì—°ê²° ì‹œë„ ===")
        host = os.getenv('MARIADB_HOST', 'my-mariadb')
        user = os.getenv('MARIADB_USER', 'testuser')
        password = os.getenv('MARIADB_PASSWORD')
        database = "testdb"
        
        logger.info(f"ì—°ê²° ì •ë³´: host={host}, user={user}, database={database}")
        logger.debug(f"ì—°ê²° ì‹œì‘ ì‹œê°„: {start_time}")
        
        connection = mysql.connector.connect(
            host=host,
            user=user,
            password=password,
            port=3306,
            database=database,
            connect_timeout=30
        )
        
        connection_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"MariaDB ì—°ê²° ì„±ê³µ! (ì†Œìš”ì‹œê°„: {connection_time:.3f}ì´ˆ)")
        logger.debug(f"ì—°ê²° ID: {connection.connection_id if hasattr(connection, 'connection_id') else 'N/A'}")
        
        return connection
    except Exception as e:
        connection_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"MariaDB ì—°ê²° ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {connection_time:.3f}ì´ˆ): {str(e)}")
        logger.error(f"ì—°ê²° ì‹œë„í•œ ì •ë³´: host={host}, user={user}, database={database}")
        logger.error(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        raise e

# Redis ì—°ê²° í•¨ìˆ˜ (ì½ê¸°/ì“°ê¸°ìš©)
def get_redis_connection():
    start_time = datetime.now()
    try:
        host = os.getenv('REDIS_HOST', 'redis-master.sungho.svc.cluster.local')
        logger.debug(f"Redis ë§ˆìŠ¤í„° ì—°ê²° ì‹œë„: {host}:6379")
        
        redis_client = redis.Redis(
            host=host,
            port=6379,
            username='default',  # Redis ê¸°ë³¸ ì‚¬ìš©ìëª…
            password=os.getenv('REDIS_PASSWORD'),
            decode_responses=True,
            db=0
        )
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        redis_client.ping()
        connection_time = (datetime.now() - start_time).total_seconds()
        logger.debug(f"Redis ë§ˆìŠ¤í„° ì—°ê²° ì„±ê³µ! (ì†Œìš”ì‹œê°„: {connection_time:.3f}ì´ˆ)")
        
        return redis_client
    except Exception as e:
        connection_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"Redis ë§ˆìŠ¤í„° ì—°ê²° ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {connection_time:.3f}ì´ˆ): {str(e)}")
        raise e

# Redis ì½ê¸° ì „ìš© ì—°ê²° í•¨ìˆ˜
def get_redis_readonly_connection():
    return redis.Redis(
        host=os.getenv('REDIS_REPLICA_HOST', 'redis-replicas.sungho.svc.cluster.local'),
        port=6379,
        username='default',  # Redis ê¸°ë³¸ ì‚¬ìš©ìëª…
        password=os.getenv('REDIS_PASSWORD'),
        decode_responses=True,
        db=0
    )

# Kafka Producer ì„¤ì •
def get_kafka_producer():
    start_time = datetime.now()
    try:
        servers = os.getenv('KAFKA_SERVERS', 'my-kafka:9092')
        username = os.getenv('KAFKA_USERNAME', 'user1')
        logger.debug(f"Kafka Producer ì—°ê²° ì‹œë„: {servers}, username: {username}")
        
        producer = KafkaProducer(
            bootstrap_servers=servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            security_protocol='SASL_PLAINTEXT',
            sasl_mechanism='PLAIN',
            sasl_plain_username=username,
            sasl_plain_password=os.getenv('KAFKA_PASSWORD', '')
        )
        
        connection_time = (datetime.now() - start_time).total_seconds()
        logger.debug(f"Kafka Producer ìƒì„± ì„±ê³µ! (ì†Œìš”ì‹œê°„: {connection_time:.3f}ì´ˆ)")
        
        return producer
    except Exception as e:
        connection_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"Kafka Producer ìƒì„± ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {connection_time:.3f}ì´ˆ): {str(e)}")
        raise e

# ë¡œê¹… í•¨ìˆ˜
def log_to_redis(action, details):
    start_time = datetime.now()
    try:
        logger.debug(f"Redis ë¡œê·¸ ì €ì¥ ì‹œì‘: action={action}")
        redis_client = get_redis_connection()
        
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'action': action,
            'details': details,
            'source': 'aks-demo-backend',
            'pid': os.getpid()
        }
        
        # ë¡œê·¸ ì €ì¥
        redis_client.lpush('api_logs', json.dumps(log_entry))
        redis_client.ltrim('api_logs', 0, 99)  # ìµœê·¼ 100ê°œ ë¡œê·¸ë§Œ ìœ ì§€
        
        # ë¡œê·¸ í†µê³„ ì—…ë°ì´íŠ¸
        daily_key = f"daily_logs:{datetime.now().strftime('%Y-%m-%d')}"
        redis_client.incr(daily_key)
        redis_client.expire(daily_key, 86400 * 7)  # 7ì¼ ë³´ê´€
        
        redis_client.close()
        
        log_time = (datetime.now() - start_time).total_seconds()
        logger.debug(f"Redis ë¡œê·¸ ì €ì¥ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {log_time:.3f}ì´ˆ)")
        
    except Exception as e:
        log_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"Redis ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {log_time:.3f}ì´ˆ): {str(e)}")
        print(f"Redis logging error: {str(e)}")

# API í†µê³„ ë¡œê¹…ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
def async_log_api_stats(endpoint, method, status, user_id):
    def _log():
        start_time = datetime.now()
        try:
            logger.debug(f"Kafka ë¡œê·¸ ì „ì†¡ ì‹œì‘: {method} {endpoint} - {status}")
            producer = get_kafka_producer()
            
            log_data = {
                'timestamp': datetime.now().isoformat(),
                'endpoint': endpoint,
                'method': method,
                'status': status,
                'user_id': user_id,
                'message': f"{user_id}ê°€ {method} {endpoint} í˜¸ì¶œ ({status})",
                'source': 'aks-demo-backend',
                'thread_id': threading.current_thread().ident,
                'pid': os.getpid()
            }
            
            # Kafkaë¡œ ì „ì†¡
            future = producer.send('api-logs', log_data)
            producer.flush(timeout=5)  # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
            
            log_time = (datetime.now() - start_time).total_seconds()
            logger.debug(f"Kafka ë¡œê·¸ ì „ì†¡ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {log_time:.3f}ì´ˆ)")
            
        except Exception as e:
            log_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"Kafka ë¡œê·¸ ì „ì†¡ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {log_time:.3f}ì´ˆ): {str(e)}")
            print(f"Kafka logging error: {str(e)}")
    
    # ìƒˆë¡œìš´ ìŠ¤ë ˆë“œì—ì„œ ë¡œê¹… ì‹¤í–‰
    thread = Thread(target=_log, name=f"kafka-log-{endpoint}-{method}")
    thread.start()
    logger.debug(f"Kafka ë¡œê·¸ ìŠ¤ë ˆë“œ ì‹œì‘: {thread.name}")
    
    #  # ìŠ¤ë ˆë“œ í’€ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì—… ì‹¤í–‰
    # thread_pool.submit(_log)

# ë¡œê·¸ì¸ ë°ì½”ë ˆì´í„°
def login_required(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'user_id' not in session:
            return jsonify({"status": "error", "message": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 401
        return f(*args, **kwargs)
    return decorated_function

# MariaDB ì—”ë“œí¬ì¸íŠ¸
@app.route('/db/message', methods=['POST'])
@login_required
def save_to_db():
    try:
        user_id = session['user_id']
        db = get_db_connection()
        data = request.json
        cursor = db.cursor()
        sql = "INSERT INTO messages (message, created_at) VALUES (%s, %s)"
        cursor.execute(sql, (data['message'], datetime.now()))
        db.commit()
        cursor.close()
        db.close()
        
        # ë¡œê¹…
        log_to_redis('db_insert', f"Message saved: {data['message'][:30]}...")
        
        async_log_api_stats('/db/message', 'POST', 'success', session.get('username', 'unknown'))
        return jsonify({"status": "success"})
    except Exception as e:
        async_log_api_stats('/db/message', 'POST', 'error', session.get('username', 'unknown'))
        log_to_redis('db_insert_error', str(e))
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/db/messages', methods=['GET'])
@login_required
def get_from_db():
    try:
        user_id = session['user_id']
        db = get_db_connection()
        cursor = db.cursor(dictionary=True)
        cursor.execute("SELECT * FROM messages ORDER BY created_at DESC")
        messages = cursor.fetchall()
        cursor.close()
        db.close()
        
        # ë¹„ë™ê¸° ë¡œê¹…ìœ¼ë¡œ ë³€ê²½
        async_log_api_stats('/db/messages', 'GET', 'success', session.get('username', 'unknown'))
        
        return jsonify(messages)
    except Exception as e:
        if 'user_id' in session:
            async_log_api_stats('/db/messages', 'GET', 'error', session.get('username', 'unknown'))
        return jsonify({"status": "error", "message": str(e)}), 500

# Redis ë¡œê·¸ ì¡°íšŒ (ì½ê¸° ì „ìš© ë³µì œë³¸ ì‚¬ìš©)
@app.route('/logs/redis', methods=['GET'])
def get_redis_logs():
    try:
        # Redis ì—°ê²° ì •ë³´ ë¡œê¹…
        redis_host = os.getenv('REDIS_REPLICA_HOST', 'redis-replicas.sungho.svc.cluster.local')
        redis_password = os.getenv('REDIS_PASSWORD')
        logger.info(f"Redis ì—°ê²° ì‹œë„: host={redis_host}, username=default, password={'*' * len(redis_password) if redis_password else 'None'}")
        
        redis_client = get_redis_readonly_connection()
        
        # Redis ping í…ŒìŠ¤íŠ¸
        ping_result = redis_client.ping()
        logger.info(f"Redis ping ì„±ê³µ: {ping_result}")
        
        logs = redis_client.lrange('api_logs', 0, -1)
        redis_client.close()
        
        # ë¡œê·¸ê°€ ì—†ìœ¼ë©´ ìƒ˜í”Œ ë¡œê·¸ ë°˜í™˜
        if not logs:
            sample_logs = [
                {"timestamp": datetime.now().isoformat(), "level": "INFO", "message": "Redis ì—°ê²° ì„±ê³µ", "service": "redis"},
                {"timestamp": datetime.now().isoformat(), "level": "INFO", "message": "Redis ë¡œê·¸ ì¡°íšŒ ì™„ë£Œ", "service": "redis"}
            ]
            return jsonify(sample_logs)
        
        return jsonify([json.loads(log) for log in logs])
    except Exception as e:
        logger.error(f"Redis ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

# íšŒì›ê°€ì… ì—”ë“œí¬ì¸íŠ¸
@app.route('/register', methods=['POST'])
def register():
    logger.info("=== íšŒì›ê°€ì… ìš”ì²­ ì‹œì‘ ===")
    try:
        data = request.json
        logger.info(f"ìš”ì²­ ë°ì´í„°: {data}")
        
        username = data.get('username')
        password = data.get('password')
        
        logger.info(f"ì‚¬ìš©ìëª…: {username}")
        
        if not username or not password:
            logger.warning("ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ëˆ„ë½ë¨")
            return jsonify({"status": "error", "message": "ì‚¬ìš©ìëª…ê³¼ ë¹„ë°€ë²ˆí˜¸ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤"}), 400
            
        # ë¹„ë°€ë²ˆí˜¸ í•´ì‹œí™”
        logger.info("ë¹„ë°€ë²ˆí˜¸ í•´ì‹œí™” ì¤‘...")
        hashed_password = generate_password_hash(password)
        
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œë„...")
        db = get_db_connection()
        cursor = db.cursor()
        
        logger.info("ì‚¬ìš©ìëª… ì¤‘ë³µ ì²´í¬...")
        # ì‚¬ìš©ìëª… ì¤‘ë³µ ì²´í¬
        cursor.execute("SELECT username FROM users WHERE username = %s", (username,))
        existing_user = cursor.fetchone()
        
        if existing_user:
            logger.warning(f"ì¤‘ë³µëœ ì‚¬ìš©ìëª…: {username}")
            cursor.close()
            db.close()
            return jsonify({"status": "error", "message": "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì‚¬ìš©ìëª…ì…ë‹ˆë‹¤"}), 400
        
        logger.info("ìƒˆ ì‚¬ìš©ì ë°ì´í„° ì‚½ì… ì¤‘...")
        # ì‚¬ìš©ì ì •ë³´ ì €ì¥
        sql = "INSERT INTO users (username, password) VALUES (%s, %s)"
        cursor.execute(sql, (username, hashed_password))
        db.commit()
        cursor.close()
        db.close()
        
        logger.info(f"íšŒì›ê°€ì… ì„±ê³µ: {username}")
        return jsonify({"status": "success", "message": "íšŒì›ê°€ì…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"})
        
    except mysql.connector.Error as db_error:
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {str(db_error)}")
        logger.error(f"ì˜¤ë¥˜ ì½”ë“œ: {db_error.errno}")
        logger.error(f"SQL ìƒíƒœ: {getattr(db_error, 'sqlstate', 'N/A')}")
        return jsonify({"status": "error", "message": f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {str(db_error)}"}), 500
        
    except Exception as e:
        logger.error(f"ì¼ë°˜ ì˜¤ë¥˜: {str(e)}")
        logger.error(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        logger.error(f"ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
        return jsonify({"status": "error", "message": str(e)}), 500

# ë¡œê·¸ì¸ ì—”ë“œí¬ì¸íŠ¸
@app.route('/login', methods=['POST'])
def login():
    try:
        data = request.json
        username = data.get('username')
        password = data.get('password')
        
        if not username or not password:
            return jsonify({"status": "error", "message": "ì‚¬ìš©ìëª…ê³¼ ë¹„ë°€ë²ˆí˜¸ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤"}), 400
        
        db = get_db_connection()
        cursor = db.cursor(dictionary=True)
        cursor.execute("SELECT * FROM users WHERE username = %s", (username,))
        user = cursor.fetchone()
        cursor.close()
        db.close()
        
        if user and check_password_hash(user['password'], password):
            session['user_id'] = user['id']  # ì„¸ì…˜ì— ì‚¬ìš©ì ID ì €ì¥
            session['username'] = username  # ì„¸ì…˜ì— ì‚¬ìš©ìëª… ì €ì¥
            
            # Redis ì„¸ì…˜ ì €ì¥ (ì„ íƒì )
            try:
                redis_client = get_redis_connection()
                session_data = {
                    'user_id': user['id'],
                    'username': username,
                    'login_time': datetime.now().isoformat()
                }
                redis_client.set(f"session:{username}", json.dumps(session_data))
                redis_client.expire(f"session:{username}", 3600)
            except Exception as redis_error:
                print(f"Redis session error: {str(redis_error)}")
                # Redis ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
            
            return jsonify({
                "status": "success", 
                "message": "ë¡œê·¸ì¸ ì„±ê³µ",
                "username": username
            })
        
        return jsonify({"status": "error", "message": "ì˜ëª»ëœ ì¸ì¦ ì •ë³´"}), 401
        
    except Exception as e:
        print(f"Login error: {str(e)}")  # ì„œë²„ ë¡œê·¸ì— ì—ëŸ¬ ì¶œë ¥
        return jsonify({"status": "error", "message": "ë¡œê·¸ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}), 500

# ë¡œê·¸ì•„ì›ƒ ì—”ë“œí¬ì¸íŠ¸
@app.route('/logout', methods=['POST'])
def logout():
    try:
        if 'user_id' in session:
            username = session.get('username', '')
            if username:
                redis_client = get_redis_connection()
                redis_client.delete(f"session:{username}")
            session.pop('user_id', None)
            session.pop('username', None)
        return jsonify({"status": "success", "message": "ë¡œê·¸ì•„ì›ƒ ì„±ê³µ"})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

# ë©”ì‹œì§€ ì €ì¥ ì—”ë“œí¬ì¸íŠ¸
@app.route('/messages', methods=['POST'])
@login_required
def save_message():
    try:
        data = request.json
        message_text = data.get('message', '')
        user_id = session['user_id']
        
        if not message_text:
            return jsonify({"status": "error", "message": "ë©”ì‹œì§€ ë‚´ìš©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤"}), 400
        
        # DBì— ë©”ì‹œì§€ ì €ì¥
        db = get_db_connection()
        cursor = db.cursor()
        sql = "INSERT INTO messages (user_id, message) VALUES (%s, %s)"
        cursor.execute(sql, (user_id, message_text))
        db.commit()
        cursor.close()
        db.close()
        
        # Redis ë¡œê¹… ì¶”ê°€
        log_to_redis('message_save', f"Message saved by {session.get('username', 'unknown')}: {message_text[:30]}...")
        
        logger.info(f"ë©”ì‹œì§€ ì €ì¥ ì„±ê³µ: ì‚¬ìš©ì {session.get('username', 'unknown')}, ë©”ì‹œì§€: {message_text}")
        return jsonify({"status": "success", "message": "ë©”ì‹œì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤"})
        
    except Exception as e:
        # ì—ëŸ¬ ì‹œì—ë„ Redis ë¡œê¹…
        log_to_redis('message_save_error', f"Error saving message: {str(e)}")
        logger.error(f"ë©”ì‹œì§€ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

# ë©”ì‹œì§€ ê²€ìƒ‰ (DBì—ì„œ ê²€ìƒ‰)
@app.route('/messages/search', methods=['GET'])
@login_required
def search_messages():
    try:
        query = request.args.get('q', '')
        user_filter = request.args.get('user', '')  # íŠ¹ì • ìœ ì €ë¡œ í•„í„°ë§
        
        # DBì—ì„œ ê²€ìƒ‰ (JOINìœ¼ë¡œ ìœ ì €ëª… í¬í•¨)
        db = get_db_connection()
        cursor = db.cursor(dictionary=True)
        
        if user_filter:
            # íŠ¹ì • ìœ ì €ì˜ ë©”ì‹œì§€ë§Œ ê²€ìƒ‰
            sql = """
                SELECT m.id, m.message, m.created_at, u.username 
                FROM messages m 
                JOIN users u ON m.user_id = u.id 
                WHERE m.message LIKE %s AND u.username LIKE %s 
                ORDER BY m.created_at DESC
            """
            cursor.execute(sql, (f"%{query}%", f"%{user_filter}%"))
        else:
            # ëª¨ë“  ë©”ì‹œì§€ ê²€ìƒ‰
            sql = """
                SELECT m.id, m.message, m.created_at, u.username 
                FROM messages m 
                JOIN users u ON m.user_id = u.id 
                WHERE m.message LIKE %s 
                ORDER BY m.created_at DESC
            """
            cursor.execute(sql, (f"%{query}%",))
        
        results = cursor.fetchall()
        cursor.close()
        db.close()
        
        # Redis ë¡œê¹… ì¶”ê°€
        log_to_redis('message_search', f"Search query: '{query}', user_filter: '{user_filter}', results: {len(results)}")
        
        logger.info(f"ë©”ì‹œì§€ ê²€ìƒ‰ ì„±ê³µ: ì¿¼ë¦¬={query}, ìœ ì €í•„í„°={user_filter}, ê²°ê³¼ìˆ˜={len(results)}")
        return jsonify({"status": "success", "data": results})
        
    except Exception as e:
        # ì—ëŸ¬ ì‹œì—ë„ Redis ë¡œê¹…
        log_to_redis('message_search_error', f"Error searching messages: {str(e)}")
        logger.error(f"ë©”ì‹œì§€ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

# ìœ ì €ë³„ ë©”ì‹œì§€ ì¡°íšŒ
@app.route('/messages/user/<username>', methods=['GET'])
@login_required
def get_user_messages(username):
    try:
        # DBì—ì„œ íŠ¹ì • ìœ ì €ì˜ ë©”ì‹œì§€ ì¡°íšŒ
        db = get_db_connection()
        cursor = db.cursor(dictionary=True)
        sql = """
            SELECT m.id, m.message, m.created_at, u.username 
            FROM messages m 
            JOIN users u ON m.user_id = u.id 
            WHERE u.username = %s 
            ORDER BY m.created_at DESC
        """
        cursor.execute(sql, (username,))
        results = cursor.fetchall()
        cursor.close()
        db.close()
        
        # Redis ë¡œê¹… ì¶”ê°€
        log_to_redis('user_messages', f"User messages retrieved for: {username}, count: {len(results)}")
        
        logger.info(f"ìœ ì €ë³„ ë©”ì‹œì§€ ì¡°íšŒ ì„±ê³µ: {username}, ë©”ì‹œì§€ìˆ˜={len(results)}")
        return jsonify({"status": "success", "data": results})
        
    except Exception as e:
        # ì—ëŸ¬ ì‹œì—ë„ Redis ë¡œê¹…
        log_to_redis('user_messages_error', f"Error retrieving user messages for {username}: {str(e)}")
        logger.error(f"ìœ ì €ë³„ ë©”ì‹œì§€ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

# ëª¨ë“  ë©”ì‹œì§€ ì¡°íšŒ (ê´€ë¦¬ììš©)
@app.route('/messages', methods=['GET'])
@login_required
def get_all_messages():
    try:
        # DBì—ì„œ ëª¨ë“  ë©”ì‹œì§€ ì¡°íšŒ (JOINìœ¼ë¡œ ìœ ì €ëª… í¬í•¨)
        db = get_db_connection()
        cursor = db.cursor(dictionary=True)
        sql = """
            SELECT m.id, m.message, m.created_at, u.username 
            FROM messages m 
            JOIN users u ON m.user_id = u.id 
            ORDER BY m.created_at DESC
        """
        cursor.execute(sql)
        results = cursor.fetchall()
        cursor.close()
        db.close()
        
        # Redis ë¡œê¹… ì¶”ê°€
        log_to_redis('all_messages', f"All messages retrieved, count: {len(results)}")
        
        logger.info(f"ì „ì²´ ë©”ì‹œì§€ ì¡°íšŒ ì„±ê³µ: ë©”ì‹œì§€ìˆ˜={len(results)}")
        return jsonify({"status": "success", "data": results})
        
    except Exception as e:
        # ì—ëŸ¬ ì‹œì—ë„ Redis ë¡œê¹…
        log_to_redis('all_messages_error', f"Error retrieving all messages: {str(e)}")
        logger.error(f"ì „ì²´ ë©”ì‹œì§€ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

# Kafka ë¡œê·¸ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸
@app.route('/logs/kafka', methods=['GET'])
@login_required
def get_kafka_logs():
    try:
        consumer = KafkaConsumer(
            'api-logs',
            bootstrap_servers=os.getenv('KAFKA_SERVERS', 'my-kafka:9092'),
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            security_protocol='SASL_PLAINTEXT',
            sasl_mechanism='PLAIN',
            sasl_plain_username=os.getenv('KAFKA_USERNAME', 'user1'),
            sasl_plain_password=os.getenv('KAFKA_PASSWORD', ''),
            group_id='api-logs-viewer',
            auto_offset_reset='earliest',
            consumer_timeout_ms=5000
        )
        
        logs = []
        try:
            for message in consumer:
                logs.append({
                    'timestamp': message.value['timestamp'],
                    'endpoint': message.value['endpoint'],
                    'method': message.value['method'],
                    'status': message.value['status'],
                    'user_id': message.value['user_id'],
                    'message': message.value['message']
                })
                if len(logs) >= 100:
                    break
        finally:
            consumer.close()
        
        # ì‹œê°„ ì—­ìˆœìœ¼ë¡œ ì •ë ¬
        logs.sort(key=lambda x: x['timestamp'], reverse=True)
        return jsonify(logs)
    except Exception as e:
        print(f"Kafka log retrieval error: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

# ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸
@app.route('/metrics')
def metrics_endpoint():
    return generate_latest(), 200, {'Content-Type': CONTENT_TYPE_LATEST}

# ìš”ì²­ ë¡œê¹… ë° ë©”íŠ¸ë¦­ ë¯¸ë“¤ì›¨ì–´
@app.before_request
def log_request_info():
    # ìš”ì²­ ì‹œì‘ ì‹œê°„ ì €ì¥
    request.start_time = datetime.now()
    request.request_id = f"{datetime.now().strftime('%Y%m%d%H%M%S')}-{os.getpid()}-{threading.current_thread().ident}"
    
    logger.info("=== ìƒˆë¡œìš´ ìš”ì²­ ===")
    logger.info(f"ìš”ì²­ ID: {request.request_id}")
    logger.info(f"ìš”ì²­ ë°©ë²•: {request.method}")
    logger.info(f"ìš”ì²­ URL: {request.url}")
    logger.info(f"ìš”ì²­ ê²½ë¡œ: {request.path}")
    logger.info(f"í´ë¼ì´ì–¸íŠ¸ IP: {request.remote_addr}")
    logger.info(f"User-Agent: {request.headers.get('User-Agent', 'N/A')}")
    logger.info(f"Content-Type: {request.headers.get('Content-Type', 'N/A')}")
    logger.info(f"ì„¸ì…˜ ID: {session.get('user_id', 'anonymous')}")
    
    if request.is_json and request.path not in ['/login', '/register']:  # ë¯¼ê°í•œ ë°ì´í„° ì œì™¸
        logger.debug(f"ìš”ì²­ ë°ì´í„°: {request.get_json()}")
    
    # í™œì„± ì—°ê²° ìˆ˜ ì—…ë°ì´íŠ¸
    try:
        redis_client = get_redis_connection()
        active_requests_key = "active_requests"
        redis_client.incr(active_requests_key)
        redis_client.expire(active_requests_key, 300)  # 5ë¶„ TTL
        redis_client.close()
    except Exception as e:
        logger.debug(f"í™œì„± ìš”ì²­ ìˆ˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

@app.after_request
def log_response_info(response):
    # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
    if hasattr(request, 'start_time'):
        response_time = (datetime.now() - request.start_time).total_seconds()
        request_id = getattr(request, 'request_id', 'unknown')
        
        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        REQUEST_COUNT.labels(
            method=request.method,
            endpoint=request.path,
            status=str(response.status_code)
        ).inc()
        
        REQUEST_DURATION.labels(
            method=request.method,
            endpoint=request.path
        ).observe(response_time)
        
        logger.info(f"ìš”ì²­ ID: {request_id}")
        logger.info(f"ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        logger.info(f"ì‘ë‹µ ì‹œê°„: {response_time:.3f}ì´ˆ")
        logger.info(f"ì‘ë‹µ í¬ê¸°: {response.content_length or len(response.get_data())} bytes")
        
        # ëŠë¦° ìš”ì²­ ê²½ê³ 
        if response_time > 2.0:
            logger.warning(f"ëŠë¦° ìš”ì²­ ê°ì§€! {request.method} {request.path} - {response_time:.3f}ì´ˆ")
        
        # í™œì„± ì—°ê²° ìˆ˜ ê°ì†Œ
        try:
            redis_client = get_redis_connection()
            redis_client.decr("active_requests")
            redis_client.close()
        except Exception as e:
            logger.debug(f"í™œì„± ìš”ì²­ ìˆ˜ ê°ì†Œ ì‹¤íŒ¨: {str(e)}")
    
    logger.info("=== ìš”ì²­ ì™„ë£Œ ===")
    return response

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True) 